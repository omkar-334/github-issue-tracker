[
  {
    "repo": "pytorch/executorch",
    "id": 2299434866,
    "number": 3632,
    "title": "llama2 '8da4w-gptq' quantization fails",
    "url": "https://github.com/pytorch/executorch/issues/3632",
    "created_at": "2024-05-16T06:08:38Z",
    "user": "Liming-Wang",
    "labels": [
      "triaged",
      "module: quantization"
    ],
    "has_linked_pr": false,
    "linked_pr_url": "",
    "archived": true
  },
  {
    "repo": "vllm-project/vllm",
    "id": 2570879010,
    "number": 9129,
    "title": "[Misc]: CMake Clean-up / Refactor Tasks",
    "url": "https://github.com/vllm-project/vllm/issues/9129",
    "created_at": "2024-10-07T16:07:04Z",
    "user": "LucasWilkinson",
    "labels": [
      "help wanted",
      "good first issue",
      "keep-open",
      "unstale"
    ],
    "has_linked_pr": false,
    "linked_pr_url": "",
    "archived": true
  },
  {
    "repo": "astral-sh/ruff",
    "id": 2744304095,
    "number": 15031,
    "title": "Support `grouped` output format for `--statistics`",
    "url": "https://github.com/astral-sh/ruff/issues/15031",
    "created_at": "2024-12-17T08:52:54Z",
    "user": "un-pogaz",
    "labels": [
      "cli"
    ],
    "has_linked_pr": false,
    "linked_pr_url": "",
    "archived": true
  }
]
