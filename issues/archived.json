[
  {
    "repo": "pytorch/pytorch",
    "id": 1438462781,
    "number": 88576,
    "title": "Dynamo handling for all methods of torch.Generator",
    "url": "https://github.com/pytorch/pytorch/issues/88576",
    "created_at": "2022-11-07T14:30:44Z",
    "user": "anjali411",
    "labels": [
      "triaged",
      "enhancement",
      "module: dynamo",
      "dynamo-variable-tracker"
    ],
    "has_linked_pr": false,
    "linked_pr_url": "",
    "archived": true
  },
  {
    "repo": "pytorch/pytorch",
    "id": 2468979965,
    "number": 133629,
    "title": "RuntimeError: free_upper_bound + pytorch_used_bytes[device]",
    "url": "https://github.com/pytorch/pytorch/issues/133629",
    "created_at": "2024-08-15T21:14:54Z",
    "user": "Creepybits",
    "labels": [
      "module: cuda",
      "triaged",
      "module: CUDACachingAllocator"
    ],
    "has_linked_pr": false,
    "linked_pr_url": "",
    "archived": true
  },
  {
    "repo": "pytorch/pytorch",
    "id": 2525880722,
    "number": 136065,
    "title": "xpu: set of aten ops are missing for Huggingface Transformers",
    "url": "https://github.com/pytorch/pytorch/issues/136065",
    "created_at": "2024-09-14T00:04:50Z",
    "user": "dvrogozh",
    "labels": [
      "triaged",
      "module: xpu"
    ],
    "has_linked_pr": false,
    "linked_pr_url": "",
    "archived": true
  }
]
