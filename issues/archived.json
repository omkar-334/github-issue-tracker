[
  {
    "repo": "huggingface/tokenizers",
    "id": 2190572719,
    "number": 1473,
    "title": "Assign `<unusedXX>` tokens with `special_tokens` without growing vocab size",
    "url": "https://github.com/huggingface/tokenizers/issues/1473",
    "created_at": "2024-03-17T09:40:28Z",
    "user": "jacobwjs",
    "labels": [
      "Stale",
      "Feature Request",
      "planned"
    ],
    "has_linked_pr": false,
    "linked_pr_url": "",
    "archived": true
  },
  {
    "repo": "pytorch/ao",
    "id": 2451377185,
    "number": 606,
    "title": "[llama] Use horizontal fusion trick from Attention for FeedForward",
    "url": "https://github.com/pytorch/ao/issues/606",
    "created_at": "2024-08-06T17:32:26Z",
    "user": "cpuhrsch",
    "labels": [
      "good first issue"
    ],
    "has_linked_pr": false,
    "linked_pr_url": "",
    "archived": true
  }
]
